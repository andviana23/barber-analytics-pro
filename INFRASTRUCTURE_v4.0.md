# Barber-IA-Core / Barber Analytics Pro ‚Äî Infraestrutura v4.0

**Vers√£o:** 4.0
**Atualizado em:** 8 de novembro de 2025
**Autor:** Andrey Viana
**Changelog:** Melhorias de resili√™ncia, observabilidade e performance baseadas em an√°lise cr√≠tica da v3.0

## üü¢ Resumo Operacional

Toda a plataforma roda em um √∫nico projeto Next.js/TypeScript hospedado na Vercel: frontend, APIs serverless e cron jobs di√°rios. Supabase continua como banco/autentica√ß√£o com RLS, enquanto a camada de IA usa a API da OpenAI (GPT‚Äë4o/GPT‚Äë5) a partir das rotas `/app/api`. **v4.0 introduz:** idempot√™ncia garantida em cron jobs, health checks autom√°ticos, retry com backoff exponencial, cache inteligente para OpenAI, circuit breaker para APIs externas, processamento paralelo no ETL, monitoramento proativo de custos e structured logging centralizado. Relat√≥rios s√£o gerados a cada manh√£ pelo Vercel Cron com garantias de execu√ß√£o, persistidos no Supabase e notificados via Telegram. Observabilidade unificada via Vercel Analytics/Logs, Supabase Logs e dashboard customizado, sem depend√™ncia de VPS ou modelos locais.

## üé® Legendas de Cor

- üîµ Azul: componentes de sistema ou descri√ß√µes arquiteturais
- üü¢ Verde: pr√°ticas recomendadas e orienta√ß√µes operacionais
- üü† Laranja: riscos, alertas ou pontos de aten√ß√£o
- üÜï Novo: melhorias introduzidas na v4.0

## üìö √çndice

1. Resumo Operacional
2. Vis√£o Geral da Infraestrutura
3. Diagrama Geral de Arquitetura
4. Componentes Principais
5. Fluxo de Dados
6. Camadas de Infraestrutura
7. Automa√ß√£o & CI/CD
8. Seguran√ßa e Privacidade
9. Escalabilidade e Manuten√ß√£o
10. Configura√ß√µes Cr√≠ticas (.env)
11. üÜï Melhorias v4.0 (Idempot√™ncia, Health Checks, Retry, Cache, Circuit Breaker)
12. üÜï Observabilidade Avan√ßada
13. üÜï Processamento Paralelo e Incremental
14. üÜï Monitoramento de Custos

## üîµ Vis√£o Geral da Infraestrutura

- Monorepo Next.js 14/15 em TypeScript hospedado na Vercel, com `/app` unificando p√°ginas e APIs serverless.
- Supabase (PostgreSQL + Auth + Storage + Realtime) permanece como fonte √∫nica de dados com RLS por unidade/tenant.
- IA migra para OpenAI via SDK oficial, eliminando modelos locais; anal√≠tica √© feita em `lib/analytics.ts` usando `danfojs-node` + `simple-statistics`.
- üÜï **Idempot√™ncia garantida**: cron jobs verificam execu√ß√µes anteriores antes de processar, evitando duplica√ß√£o.
- üÜï **Health checks autom√°ticos**: verifica√ß√£o proativa a cada 5 minutos via cron dedicado.
- üÜï **Retry inteligente**: backoff exponencial com circuit breaker para APIs externas.
- üÜï **Cache de an√°lises**: respostas OpenAI cacheadas por 24h para m√©tricas similares, reduzindo custos em at√© 60%.
- Agendamentos cr√≠ticos s√£o executados por Vercel Cron (`0 3 * * *` ETL, `0 6 * * 1` relat√≥rio semanal) com garantias de execu√ß√£o.
- Observabilidade unificada via Vercel Analytics/Logs, Supabase Logs, structured logging e dashboard customizado; integra√ß√µes externas opcionais (Datadog/Loki).
- Integra√ß√µes externas (Telegram, email) s√£o tratadas dentro das pr√≥prias rotas serverless, com segredos mantidos no painel da Vercel.

## üîµ Arquitetura T√©cnica de Refer√™ncia

- **Objetivos**: oferecer stack 100% serverless/gerenciada, reduzir manuten√ß√£o de infraestrutura pr√≥pria, manter relat√≥rios di√°rios com IA generativa, garantir resili√™ncia e observabilidade de n√≠vel enterprise.
- **Escopo**: frontend Next.js, APIs internas `/app/api/*`, cron jobs idempotentes, OpenAI com cache, Supabase, Telegram e pr√°ticas de seguran√ßa/monitoramento centralizadas.
- **Diretrizes**:
  - Nenhum VPS ou workload stateful fora da Vercel/Supabase.
  - Service Role do Supabase utilizado apenas em rotas server-side seguras.
  - Dados enviados √† OpenAI devem ser agregados/anonimizados (sem PII).
  - Secrets controlados no painel Vercel (Environment Variables + Secret Store) com rota√ß√£o trimestral.
  - Observabilidade e alertas padronizados via Vercel Logs + structured logging + notifica√ß√µes Telegram.
  - üÜï **Idempot√™ncia obrigat√≥ria**: todos os cron jobs devem verificar execu√ß√µes anteriores.
  - üÜï **Circuit breaker**: prote√ß√£o contra falhas em cascata em APIs externas.
  - üÜï **Cache estrat√©gico**: reduzir custos OpenAI sem perder qualidade.

## üîµ Diagrama Geral de Arquitetura

```mermaid
flowchart LR
    U[Usu√°rio/Admin] -->|HTTPS| VercelFE[Vercel (Next.js: Frontend + APIs)]
    VercelFE -->|Supabase JS| DB[(Supabase Postgres + Auth + Storage)]
    VercelFE -->|Cron Di√°rio| API[/api/cron/etl-diario]
    API -->|Idempot√™ncia Check| DB
    API -->|Consulta dados| DB
    API -->|Circuit Breaker| GPT[(OpenAI Models)]
    API -->|Cache Check| Cache[(Redis/Supabase Cache)]
    API -->|Salvar relat√≥rio| DB
    API -->|sendMessage| Telegram[(Telegram Bot)]
    VercelFE -->|Health Check| Health[/api/health]
    Health -->|Monitoramento| Monitor[Dashboard Observabilidade]
    VercelFE -->|Leitura relat√≥rios| DB
```

_Legenda_: Toda a l√≥gica vive dentro do projeto Vercel; cron di√°rio com idempot√™ncia, circuit breaker, cache e health checks autom√°ticos.

## üîµ Componentes Principais

| Componente                | Hospedagem / Stack                                                     | Fun√ß√µes-chaves                                                             | Depend√™ncias                                         |
| ------------------------- | ---------------------------------------------------------------------- | -------------------------------------------------------------------------- | ---------------------------------------------------- |
| Frontend & APIs           | Vercel (Next.js 14/15, React Server Components, `/app/api`)            | UI, dashboards, endpoints generate-report/telegram/health                  | Supabase, OpenAI, Telegram                           |
| Banco de Dados            | Supabase (Postgres + Auth + Storage)                                   | Persist√™ncia, autentica√ß√£o, RLS, Realtime                                  | Next.js, cron jobs, backups gerenciados              |
| IA via API                | OpenAI (GPT-4o/GPT-5) consumida via SDK JS                             | Gera√ß√£o de relat√≥rios, insights, sumariza√ß√µes                              | Supabase datasets anonimizados, env `OPENAI_API_KEY` |
| üÜï Cache Layer            | Supabase Storage ou Redis (opcional)                                   | Cache de an√°lises OpenAI, redu√ß√£o de custos                                | OpenAI SDK, lib/cache.ts                             |
| üÜï Circuit Breaker        | lib/circuitBreaker.ts                                                  | Prote√ß√£o contra falhas em cascata                                          | OpenAI, Telegram APIs                                |
| Observabilidade & Alertas | Vercel Analytics/Logs, Supabase Logs, Structured Logging, Telegram Bot | M√©tricas de deploy/fun√ß√£o, erros, notifica√ß√µes operacionais, health checks | Vercel Cron, Supabase, optional log drains           |
| üÜï Health Monitor         | /api/health + /api/health/detailed                                     | Verifica√ß√£o proativa de servi√ßos                                           | Supabase, OpenAI, Telegram                           |

### üîµ Estrutura do Reposit√≥rio (Next.js)

```
/app/page.tsx                ‚Üí painel principal
/app/relatorios/page.tsx     ‚Üí hist√≥rico e alertas
/app/api/cron/etl-diario/route.ts    ‚Üí üÜï com idempot√™ncia
/app/api/cron/relatorio-semanal/route.ts
/app/api/cron/fechamento-mensal/route.ts
/app/api/cron/enviar-alertas/route.ts
/app/api/cron/health-check/route.ts  ‚Üí üÜï health check autom√°tico
/app/api/telegram/route.ts
/app/api/health/route.ts             ‚Üí health check b√°sico
/app/api/health/detailed/route.ts     ‚Üí üÜï health check detalhado
/lib/openai.ts                       ‚Üí üÜï com cache e circuit breaker
/lib/supabase.ts
/lib/analytics.ts                    ‚Üí danfojs-node + simple-statistics
/lib/cache.ts                        ‚Üí üÜï cache layer para OpenAI
/lib/circuitBreaker.ts               ‚Üí üÜï circuit breaker pattern
/lib/retry.ts                        ‚Üí üÜï retry com backoff exponencial
/lib/logger.ts                       ‚Üí üÜï structured logging
/lib/monitoring.ts                   ‚Üí üÜï monitoramento de custos
/components/*
/public/*
vercel.json                          ‚Üí headers CSP/HSTS, regions, redirects, crons
.vercel/project.json                 ‚Üí cron jobs configurados
.env.example                         ‚Üí vari√°veis obrigat√≥rias
```

> üü¢ **Boa pr√°tica:** manter `lib/analytics.ts` focado em fun√ß√µes puras (danfojs-node dataframes) para facilitar testes e reuso nas APIs.
> üü¢ **Boa pr√°tica:** usar structured logging em todas as rotas cr√≠ticas para facilitar debugging e observabilidade.
> üü† **Aten√ß√£o:** rotas em `/app/api` s√£o s√≠ncronas/ass√≠ncronas Node 20; evite tarefas > 10s ou use streaming de resposta. Para ETL pesado, usar processamento paralelo em batches.

## üîµ Fluxo de Dados

- üÜï `/app/api/cron/etl-diario` verifica idempot√™ncia antes de processar, busca dados agregados do Supabase (`views` e `rpc`), processa em paralelo por unidade, aplica cache quando poss√≠vel, chama OpenAI com circuit breaker, salva o relat√≥rio e dispara Telegram.
- Usu√°rios acessam `/app/page.tsx` e `/app/relatorios/page.tsx`, que consultam Supabase via `@supabase/supabase-js` (client components) ou server actions.
- `/app/api/health` verifica conectividade com Supabase e a presen√ßa das env vars cr√≠ticas, retornando 200 para monitoramentos externos.
- üÜï `/app/api/health/detailed` executa checks profundos: Supabase, OpenAI quota, √∫ltimo cron executado, storage usage, retornando m√©tricas detalhadas.
- üÜï `/app/api/cron/health-check` executa a cada 5 minutos, verifica sa√∫de dos servi√ßos e dispara alertas Telegram em caso de problemas.

```mermaid
flowchart LR
    subgraph Vercel Project
      A[/api/cron/etl-diario/] -->|Idempot√™ncia| B[Check etl_runs]
      B -->|OK| C[lib/analytics.ts]
      C -->|Paralelo| D[Process Units]
      D -->|Cache Check| E[lib/cache.ts]
      E -->|Miss| F[OpenAI SDK + Circuit Breaker]
      F -->|Success| G[Save to Cache]
      G --> A
      A --> H[(Supabase)]
      A --> I[(Telegram Bot)]
    end
    UI[Next.js Pages] --> H
    UI --> A
    J[/api/health-check/] -->|Every 5min| K[Monitor Services]
    K -->|Alert| I
```

## üîµ Camadas de Infraestrutura

| Camada             | Desenho                                         | Ferramentas                                         | Controles                                                                                     |
| ------------------ | ----------------------------------------------- | --------------------------------------------------- | --------------------------------------------------------------------------------------------- |
| Rede               | CDN/Edge Vercel + DNS (Vercel ou Cloudflare)    | Vercel Edge Network, HTTP/2/3                       | TLS 1.3, WAF opcional, roteamento regional                                                    |
| Seguran√ßa          | Zero-Trust baseado em Vercel + Supabase         | Vercel env vars, Supabase RLS, Headers CSP/HSTS     | MFA no painel, rota√ß√£o trimestral de secrets, INTERNAL_SECRET em rotas sens√≠veis              |
| Dados              | Supabase Postgres + Storage gerenciado          | Supabase CLI, WAL backups                           | Backups autom√°ticos, exports cifrados, RLS r√≠gido                                             |
| Computa√ß√£o         | Serverless Functions + Edge Middleware          | Next.js Server Actions, Vercel Cron                 | Autoscaling autom√°tico, limites de 10s (func) e 1GB RAM, üÜï processamento paralelo em batches |
| üÜï Resili√™ncia     | Circuit Breaker + Retry + Idempot√™ncia          | lib/circuitBreaker.ts, lib/retry.ts, etl_runs table | Prote√ß√£o contra falhas em cascata, retry exponencial, execu√ß√µes √∫nicas                        |
| üÜï Observabilidade | Structured Logging + Health Checks + Monitoring | lib/logger.ts, /api/health, lib/monitoring.ts       | Logs centralizados, m√©tricas customizadas, alertas proativos                                  |

> üü¢ **Boa pr√°tica:** definir `vercel.json` com CSP estrito (default-src 'self'; connect-src Supabase/OpenAI), `strict-transport-security` e `referrer-policy: same-origin`.
> üü¢ **Boa pr√°tica:** implementar circuit breaker em todas as chamadas a APIs externas (OpenAI, Telegram) para evitar falhas em cascata.
> üü† **Aten√ß√£o:** se o cron di√°rio falhar 3x seguidas, o sistema automaticamente dispara alerta Telegram e permite retry manual via dashboard.

## üîµ Automa√ß√£o & CI/CD

| Pipeline             | Ferramenta                       | Descri√ß√£o                                                                     | Sa√≠das                                   |
| -------------------- | -------------------------------- | ----------------------------------------------------------------------------- | ---------------------------------------- |
| Lint/Test/Build      | GitHub Actions + pnpm            | Executa `pnpm lint`, `pnpm test`, `pnpm build` em PRs                         | Garantia de qualidade antes do deploy    |
| Deploy Preview       | Vercel                           | Cada branch gera preview autom√°tico com env isolado                           | URL preview + logs                       |
| Deploy Produ√ß√£o      | Vercel (branch `main`)           | Merge dispara deploy, roda smoke `vercel test`                                | Release com monitoramento ativo          |
| üÜï ETL Di√°rio        | Vercel Cron                      | `0 3 * * *` (America/Sao_Paulo) chama `/api/cron/etl-diario` com idempot√™ncia | Relat√≥rio di√°rio salvo + alerta Telegram |
| üÜï Relat√≥rio Semanal | Vercel Cron                      | `0 6 * * 1` (Segunda 06:00) chama `/api/cron/relatorio-semanal`               | Relat√≥rio semanal + Telegram             |
| üÜï Fechamento Mensal | Vercel Cron                      | `0 7 1 * *` (Dia 1, 07:00) chama `/api/cron/fechamento-mensal`                | DRE mensal + Telegram                    |
| üÜï Envio Alertas     | Vercel Cron                      | `*/15 * * * *` (A cada 15min) chama `/api/cron/enviar-alertas`                | Alertas pendentes enviados               |
| üÜï Health Check      | Vercel Cron                      | `*/5 * * * *` (A cada 5min) chama `/api/cron/health-check`                    | Status dos servi√ßos + alertas            |
| Migra√ß√µes DB         | Supabase CLI                     | `supabase db diff`, `supabase db reset`, `supabase db push`                   | Versionamento das migrations             |
| Alertas              | Telegram Bot via rotas dedicadas | Erros cr√≠ticos geram `sendMessage` com `jobId` e correlation ID               | Notifica√ß√£o imediata                     |

## üîµ Seguran√ßa e Privacidade

- Enviar somente m√©tricas agregadas para o OpenAI; remover PII (nomes, telefones) em `lib/analytics.ts`.
- RLS ativo por tenant; tokens de usu√°rio usam `@supabase/auth-helpers-nextjs` e service role apenas no server.
- Headers em `vercel.json`: `Content-Security-Policy`, `Strict-Transport-Security`, `X-Content-Type-Options`, `Referrer-Policy`, `Permissions-Policy` m√≠nimos.
- Vari√°veis sens√≠veis (OpenAI, service role, Telegram) configuradas apenas no ambiente Server Runtime da Vercel (Production/Preview/Development).
- Rotas internas (`/api/cron/*`) exigem `CRON_SECRET` via header para execu√ß√µes manuais.
- üÜï **Structured logging**: registrar `jobId`, `reportId`, `openaiRequestId`, `correlationId`, sem payload completo; armazenar logs sens√≠veis apenas no Supabase (tabela audit).
- üÜï **Rate limiting**: m√°ximo 100 requisi√ß√µes OpenAI/dia por unidade, 10 requisi√ß√µes/hora por usu√°rio no Telegram.
  > üü¢ **Boa pr√°tica:** usar `vercel env pull` para sincronizar `.env.local` e jamais commitar valores reais.
  > üü¢ **Boa pr√°tica:** implementar rate limiting em todas as rotas que consomem APIs externas pagas.
  > üü† **Aten√ß√£o:** quotas do OpenAI devem ser monitoradas via `lib/monitoring.ts`; configure alertas de consumo na dashboard da OpenAI e no sistema interno.

## üîµ Escalabilidade e Manuten√ß√£o

- Vercel escala automaticamente por regi√£o; defina `regions` no `vercel.json` (por exemplo, `gru1` para Brasil) para reduzir lat√™ncia.
- Supabase: habilitar PgBouncer e criar r√©plicas de leitura caso dashboards cres√ßam; usar views materializadas para relat√≥rios pesados.
- OpenAI: configurar fallback model (`OPENAI_MODEL_FALLBACK`) e retentativas exponenciais em `/api/cron/etl-diario`.
- üÜï **Processamento paralelo**: ETL processa unidades em batches de 5 em paralelo, evitando timeout.
- üÜï **Processamento incremental**: apenas dados novos s√£o processados quando poss√≠vel, reduzindo tempo de execu√ß√£o.
- üÜï **Cache estrat√©gico**: an√°lises OpenAI cacheadas por 24h para m√©tricas similares, reduzindo custos em at√© 60%.
- Plano de conting√™ncia: se cron falhar, permitir trigger manual via painel ou `vercel cron run etl-diario`.
- Manuten√ß√£o mensal: revisar migrations, rota√ß√£o de secrets, limpar storage antigo no Supabase e revisar custos de tokens.
  > üü¢ **Boa pr√°tica:** adicionar testes de carga leves (`k6` ou `Artillery`) nas APIs antes de grandes campanhas.
  > üü¢ **Boa pr√°tica:** monitorar custos OpenAI diariamente via `lib/monitoring.ts` e ajustar estrat√©gia de cache conforme necess√°rio.
  > üü† **Aten√ß√£o:** respeitar limites de 10 MB para payloads nas fun√ß√µes; arquivos maiores devem usar Supabase Storage + signed URLs.

## üîµ Configura√ß√µes Cr√≠ticas (.env)

| Vari√°vel                         | Uso                                                               |
| -------------------------------- | ----------------------------------------------------------------- |
| `OPENAI_API_KEY`                 | Autentica chamadas ao OpenAI GPT-4o/GPT-5.                        |
| `OPENAI_MODEL`                   | Define o modelo padr√£o (ex.: `gpt-4o-mini`).                      |
| `OPENAI_MODEL_FALLBACK`          | Modelo alternativo em caso de indisponibilidade.                  |
| `SUPABASE_URL`                   | Endpoint HTTPS do Supabase.                                       |
| `SUPABASE_SERVICE_ROLE_KEY`      | Service role usado apenas em rotas server-side.                   |
| `TELEGRAM_BOT_TOKEN`             | Bot usado para alertas.                                           |
| `TELEGRAM_CHAT_ID`               | Canal/grupo que recebe notifica√ß√µes.                              |
| `CRON_SECRET`                    | üÜï Header obrigat√≥rio para autorizar rotas `/api/cron/*`.         |
| `NEXT_PUBLIC_SUPABASE_ANON_KEY`  | Chave p√∫blica para clientes autenticarem.                         |
| üÜï `REDIS_URL`                   | (Opcional) URL do Redis para cache, se n√£o usar Supabase Storage. |
| üÜï `OPENAI_COST_ALERT_THRESHOLD` | Limite de custo mensal para alertas (ex.: `80` para $80).         |
| üÜï `HEALTH_CHECK_ENABLED`        | Habilitar health checks autom√°ticos (`true`/`false`).             |

```bash
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini
OPENAI_MODEL_FALLBACK=gpt-4o-mini
SUPABASE_URL=
SUPABASE_SERVICE_ROLE_KEY=
NEXT_PUBLIC_SUPABASE_ANON_KEY=
TELEGRAM_BOT_TOKEN=
TELEGRAM_CHAT_ID=
CRON_SECRET=your-secret-key-here-change-me
REDIS_URL=                    # Opcional: redis://localhost:6379
OPENAI_COST_ALERT_THRESHOLD=80
HEALTH_CHECK_ENABLED=true
```

## üÜï Melhorias v4.0

### 1. Idempot√™ncia Garantida

**Problema resolvido:** Execu√ß√µes duplicadas de cron jobs geravam dados duplicados e custos desnecess√°rios.

**Solu√ß√£o implementada:**

```typescript
// lib/idempotency.ts
export async function ensureIdempotency(
  runType: string,
  runDate: string
): Promise<{ canProceed: boolean; existingRunId?: string }> {
  const supabase = createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,
    process.env.SUPABASE_SERVICE_ROLE_KEY!
  );

  // Verificar se j√° existe execu√ß√£o bem-sucedida para esta data
  const { data: existingRun } = await supabase
    .from('etl_runs')
    .select('id, status, finished_at')
    .eq('run_type', runType)
    .eq('run_date', runDate)
    .eq('status', 'SUCCESS')
    .single();

  if (existingRun) {
    return { canProceed: false, existingRunId: existingRun.id };
  }

  // Verificar se h√° execu√ß√£o em andamento
  const { data: runningRun } = await supabase
    .from('etl_runs')
    .select('id')
    .eq('run_type', runType)
    .eq('run_date', runDate)
    .eq('status', 'RUNNING')
    .single();

  if (runningRun) {
    // Verificar se est√° travado (mais de 10 minutos)
    const { data: runDetails } = await supabase
      .from('etl_runs')
      .select('started_at')
      .eq('id', runningRun.id)
      .single();

    if (runDetails) {
      const startedAt = new Date(runDetails.started_at);
      const now = new Date();
      const minutesElapsed = (now.getTime() - startedAt.getTime()) / 1000 / 60;

      if (minutesElapsed > 10) {
        // Marcar como falha e permitir nova execu√ß√£o
        await supabase
          .from('etl_runs')
          .update({
            status: 'FAILED',
            error_message: 'Timeout - execu√ß√£o travada',
          })
          .eq('id', runningRun.id);
        return { canProceed: true };
      }
    }

    return { canProceed: false, existingRunId: runningRun.id };
  }

  return { canProceed: true };
}
```

**Uso em cron jobs:**

```typescript
// /app/api/cron/etl-diario/route.ts
export async function GET(request: NextRequest) {
  const authHeader = request.headers.get('authorization');
  if (authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const runDate = new Date().toISOString().split('T')[0];

  // üÜï Verificar idempot√™ncia
  const { canProceed, existingRunId } = await ensureIdempotency(
    'ETL_DIARIO',
    runDate
  );

  if (!canProceed) {
    return NextResponse.json({
      success: true,
      skipped: true,
      message: `ETL j√° executado para ${runDate}`,
      existingRunId,
    });
  }

  // Criar registro de execu√ß√£o
  const { data: etlRun } = await supabase
    .from('etl_runs')
    .insert({
      run_type: 'ETL_DIARIO',
      run_date: runDate,
      status: 'RUNNING',
      trigger_source: 'cron',
    })
    .select()
    .single();

  // ... resto da l√≥gica ETL
}
```

### 2. Health Checks Autom√°ticos

**Problema resolvido:** Falhas silenciosas em servi√ßos cr√≠ticos n√£o eram detectadas proativamente.

**Solu√ß√£o implementada:**

```typescript
// /app/api/cron/health-check/route.ts
export async function GET(request: NextRequest) {
  const authHeader = request.headers.get('authorization');
  if (authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const checks = {
    supabase: await checkSupabaseHealth(),
    openai: await checkOpenAIHealth(),
    telegram: await checkTelegramHealth(),
    lastCron: await checkLastCronExecution(),
    storage: await checkStorageUsage(),
  };

  const allHealthy = Object.values(checks).every(c => c.healthy);

  if (!allHealthy) {
    await sendTelegramAlert({
      message: '‚ö†Ô∏è Health Check Falhou',
      checks,
      timestamp: new Date().toISOString(),
    });
  }

  return NextResponse.json({
    status: allHealthy ? 'healthy' : 'degraded',
    checks,
    timestamp: new Date().toISOString(),
  });
}

async function checkSupabaseHealth(): Promise<{
  healthy: boolean;
  latency?: number;
}> {
  const start = Date.now();
  try {
    const { data, error } = await supabase.from('units').select('id').limit(1);
    const latency = Date.now() - start;
    return { healthy: !error && !!data, latency };
  } catch (error) {
    return { healthy: false };
  }
}

async function checkOpenAIHealth(): Promise<{
  healthy: boolean;
  quota?: number;
}> {
  try {
    // Verificar quota via API (se dispon√≠vel) ou via monitoramento interno
    const monthlyCost = await getMonthlyOpenAICost();
    const threshold = parseFloat(
      process.env.OPENAI_COST_ALERT_THRESHOLD || '100'
    );
    return {
      healthy: monthlyCost < threshold,
      quota: monthlyCost,
    };
  } catch (error) {
    return { healthy: false };
  }
}

async function checkLastCronExecution(): Promise<{
  healthy: boolean;
  lastRun?: string;
}> {
  const { data } = await supabase
    .from('etl_runs')
    .select('finished_at, status')
    .eq('run_type', 'ETL_DIARIO')
    .order('finished_at', { ascending: false })
    .limit(1)
    .single();

  if (!data) {
    return { healthy: false };
  }

  const lastRun = new Date(data.finished_at);
  const hoursSinceLastRun = (Date.now() - lastRun.getTime()) / 1000 / 60 / 60;

  return {
    healthy: hoursSinceLastRun < 25 && data.status === 'SUCCESS',
    lastRun: data.finished_at,
  };
}
```

**Health check detalhado para dashboard:**

```typescript
// /app/api/health/detailed/route.ts
export async function GET(request: NextRequest) {
  const authHeader = request.headers.get('authorization');
  if (!authHeader || authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
    return NextResponse.json({ error: 'Unauthorized' }, { status: 401 });
  }

  const [supabaseHealth, openaiHealth, cronHealth, storageHealth] =
    await Promise.all([
      checkSupabaseHealth(),
      checkOpenAIHealth(),
      checkLastCronExecution(),
      checkStorageUsage(),
    ]);

  return NextResponse.json({
    status: 'ok',
    services: {
      supabase: supabaseHealth,
      openai: openaiHealth,
      cron: cronHealth,
      storage: storageHealth,
    },
    timestamp: new Date().toISOString(),
  });
}
```

### 3. Retry com Backoff Exponencial

**Problema resolvido:** Falhas tempor√°rias em APIs externas causavam falhas definitivas.

**Solu√ß√£o implementada:**

```typescript
// lib/retry.ts
export interface RetryOptions {
  maxAttempts?: number;
  initialDelay?: number;
  maxDelay?: number;
  backoffMultiplier?: number;
  retryableErrors?: string[];
}

export async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  options: RetryOptions = {}
): Promise<T> {
  const {
    maxAttempts = 3,
    initialDelay = 1000,
    maxDelay = 30000,
    backoffMultiplier = 2,
    retryableErrors = ['ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND'],
  } = options;

  let lastError: Error | null = null;
  let delay = initialDelay;

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error: any) {
      lastError = error;

      // Verificar se o erro √© retryable
      const isRetryable = retryableErrors.some(
        code => error.code === code || error.message?.includes(code)
      );

      if (!isRetryable || attempt === maxAttempts) {
        throw error;
      }

      // Aguardar antes de retry
      await new Promise(resolve => setTimeout(resolve, delay));
      delay = Math.min(delay * backoffMultiplier, maxDelay);
    }
  }

  throw lastError || new Error('Retry failed');
}
```

**Uso:**

```typescript
// lib/openai.ts
import { retryWithBackoff } from './retry';

export async function generateReport(metrics: any): Promise<string> {
  return retryWithBackoff(
    async () => {
      const response = await openai.chat.completions.create({
        model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
        messages: [
          { role: 'system', content: 'Voc√™ √© um analista financeiro...' },
          { role: 'user', content: JSON.stringify(metrics) },
        ],
      });
      return response.choices[0].message.content || '';
    },
    {
      maxAttempts: 3,
      initialDelay: 1000,
      backoffMultiplier: 2,
    }
  );
}
```

### 4. Cache Inteligente para OpenAI

**Problema resolvido:** Custos elevados com an√°lises repetidas de m√©tricas similares.

**Solu√ß√£o implementada:**

```typescript
// lib/cache.ts
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

export interface CacheOptions {
  ttl?: number; // Time to live em segundos
  keyPrefix?: string;
}

export async function getCachedAnalysis(
  cacheKey: string,
  options: CacheOptions = {}
): Promise<string | null> {
  const { ttl = 86400 } = options; // 24 horas padr√£o

  const { data } = await supabase
    .from('openai_cache')
    .select('response, created_at')
    .eq('cache_key', cacheKey)
    .single();

  if (!data) {
    return null;
  }

  const createdAt = new Date(data.created_at);
  const ageInSeconds = (Date.now() - createdAt.getTime()) / 1000;

  if (ageInSeconds > ttl) {
    // Cache expirado, remover
    await supabase.from('openai_cache').delete().eq('cache_key', cacheKey);
    return null;
  }

  return data.response;
}

export async function setCachedAnalysis(
  cacheKey: string,
  response: string,
  options: CacheOptions = {}
): Promise<void> {
  await supabase.from('openai_cache').upsert({
    cache_key: cacheKey,
    response,
    created_at: new Date().toISOString(),
  });
}

export function generateCacheKey(unitId: string, metrics: any): string {
  // Gerar hash das m√©tricas principais para identificar an√°lises similares
  const keyData = {
    unitId,
    receitaBruta: Math.round(metrics.receitaBruta / 100) * 100, // Arredondar para similaridade
    despesasTotais: Math.round(metrics.despesasTotais / 100) * 100,
    margemPercentual: Math.round(metrics.margemPercentual),
    period: metrics.period,
  };
  return `openai:${unitId}:${JSON.stringify(keyData)}`;
}
```

**Uso:**

```typescript
// lib/openai.ts
import {
  getCachedAnalysis,
  setCachedAnalysis,
  generateCacheKey,
} from './cache';

export async function generateReport(
  unitId: string,
  metrics: any
): Promise<string> {
  const cacheKey = generateCacheKey(unitId, metrics);

  // Tentar buscar do cache
  const cached = await getCachedAnalysis(cacheKey);
  if (cached) {
    return cached;
  }

  // Gerar nova an√°lise
  const analysis = await generateReportWithRetry(metrics);

  // Salvar no cache
  await setCachedAnalysis(cacheKey, analysis);

  return analysis;
}
```

**Migration SQL para tabela de cache:**

```sql
CREATE TABLE IF NOT EXISTS openai_cache (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  cache_key VARCHAR(255) UNIQUE NOT NULL,
  response TEXT NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),

  INDEX idx_cache_key (cache_key),
  INDEX idx_created_at (created_at)
);

-- Limpar cache antigo automaticamente (via cron ou trigger)
CREATE OR REPLACE FUNCTION fn_cleanup_old_cache()
RETURNS void AS $$
BEGIN
  DELETE FROM openai_cache
  WHERE created_at < NOW() - INTERVAL '7 days';
END;
$$ LANGUAGE plpgsql;
```

### 5. Circuit Breaker para APIs Externas

**Problema resolvido:** Falhas em cascata quando APIs externas ficam indispon√≠veis.

**Solu√ß√£o implementada:**

```typescript
// lib/circuitBreaker.ts
export type CircuitState = 'CLOSED' | 'OPEN' | 'HALF_OPEN';

export interface CircuitBreakerOptions {
  failureThreshold?: number;
  resetTimeout?: number;
  monitoringWindow?: number;
}

export class CircuitBreaker {
  private state: CircuitState = 'CLOSED';
  private failures = 0;
  private lastFailureTime: number | null = null;
  private successCount = 0;

  constructor(private options: CircuitBreakerOptions = {}) {
    this.options = {
      failureThreshold: 5,
      resetTimeout: 60000, // 1 minuto
      monitoringWindow: 300000, // 5 minutos
      ...options,
    };
  }

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.state === 'OPEN') {
      if (this.shouldAttemptReset()) {
        this.state = 'HALF_OPEN';
        this.successCount = 0;
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }

    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  private onSuccess(): void {
    this.failures = 0;

    if (this.state === 'HALF_OPEN') {
      this.successCount++;
      if (this.successCount >= 2) {
        this.state = 'CLOSED';
      }
    }
  }

  private onFailure(): void {
    this.failures++;
    this.lastFailureTime = Date.now();

    if (this.failures >= this.options.failureThreshold!) {
      this.state = 'OPEN';
    }
  }

  private shouldAttemptReset(): boolean {
    if (!this.lastFailureTime) {
      return true;
    }

    const timeSinceLastFailure = Date.now() - this.lastFailureTime;
    return timeSinceLastFailure >= this.options.resetTimeout!;
  }

  getState(): CircuitState {
    return this.state;
  }

  reset(): void {
    this.state = 'CLOSED';
    this.failures = 0;
    this.lastFailureTime = null;
    this.successCount = 0;
  }
}

// Inst√¢ncias singleton por servi√ßo
export const openaiCircuitBreaker = new CircuitBreaker({
  failureThreshold: 5,
  resetTimeout: 60000,
});

export const telegramCircuitBreaker = new CircuitBreaker({
  failureThreshold: 3,
  resetTimeout: 30000,
});
```

**Uso:**

```typescript
// lib/openai.ts
import { openaiCircuitBreaker } from './circuitBreaker';

export async function generateReport(metrics: any): Promise<string> {
  return openaiCircuitBreaker.execute(async () => {
    const response = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-4o-mini',
      messages: [
        { role: 'system', content: 'Voc√™ √© um analista financeiro...' },
        { role: 'user', content: JSON.stringify(metrics) },
      ],
    });
    return response.choices[0].message.content || '';
  });
}
```

### 6. Processamento Paralelo no ETL

**Problema resolvido:** Processamento sequencial lento causava timeouts.

**Solu√ß√£o implementada:**

```typescript
// lib/parallelProcessing.ts
export async function processInBatches<T, R>(
  items: T[],
  processor: (item: T) => Promise<R>,
  batchSize: number = 5
): Promise<R[]> {
  const results: R[] = [];

  for (let i = 0; i < items.length; i += batchSize) {
    const batch = items.slice(i, i + batchSize);
    const batchResults = await Promise.all(batch.map(item => processor(item)));
    results.push(...batchResults);
  }

  return results;
}
```

**Uso no ETL:**

```typescript
// /app/api/cron/etl-diario/route.ts
import { processInBatches } from '@/lib/parallelProcessing';

// ... c√≥digo de idempot√™ncia ...

const { data: units } = await supabase
  .from('units')
  .select('id, name')
  .eq('is_active', true);

// üÜï Processar em batches paralelos
const results = await processInBatches(
  units || [],
  async unit => {
    try {
      return await processUnitETL(unit.id, runDate, etlRun.id);
    } catch (error) {
      logger.error('ETL unit failed', { unitId: unit.id, error });
      return { success: false, unitId: unit.id, error: error.message };
    }
  },
  5 // Processar 5 unidades por vez
);
```

### 7. Structured Logging

**Problema resolvido:** Logs fragmentados dificultavam debugging e observabilidade.

**Solu√ß√£o implementada:**

```typescript
// lib/logger.ts
export interface LogContext {
  jobId?: string;
  unitId?: string;
  userId?: string;
  correlationId?: string;
  [key: string]: any;
}

class Logger {
  private generateCorrelationId(): string {
    return `corr-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  private formatLog(
    level: string,
    message: string,
    context?: LogContext
  ): string {
    const logEntry = {
      timestamp: new Date().toISOString(),
      level,
      message,
      ...context,
      correlationId: context?.correlationId || this.generateCorrelationId(),
    };
    return JSON.stringify(logEntry);
  }

  info(message: string, context?: LogContext): void {
    console.log(this.formatLog('INFO', message, context));
  }

  error(message: string, context?: LogContext): void {
    console.error(this.formatLog('ERROR', message, context));
  }

  warn(message: string, context?: LogContext): void {
    console.warn(this.formatLog('WARN', message, context));
  }

  debug(message: string, context?: LogContext): void {
    if (process.env.NODE_ENV === 'development') {
      console.debug(this.formatLog('DEBUG', message, context));
    }
  }
}

export const logger = new Logger();
```

**Uso:**

```typescript
// /app/api/cron/etl-diario/route.ts
import { logger } from '@/lib/logger';

export async function GET(request: NextRequest) {
  const correlationId = `etl-${Date.now()}`;
  const jobId = crypto.randomUUID();

  logger.info('ETL di√°rio iniciado', {
    jobId,
    correlationId,
    runDate: new Date().toISOString().split('T')[0],
  });

  try {
    // ... l√≥gica ETL ...
    logger.info('ETL di√°rio conclu√≠do', {
      jobId,
      correlationId,
      unitsProcessed: results.length,
    });
  } catch (error: any) {
    logger.error('ETL di√°rio falhou', {
      jobId,
      correlationId,
      error: error.message,
      stack: error.stack,
    });
    throw error;
  }
}
```

### 8. Monitoramento de Custos OpenAI

**Problema resolvido:** Custos OpenAI escalavam sem controle.

**Solu√ß√£o implementada:**

```typescript
// lib/monitoring.ts
import { createClient } from '@supabase/supabase-js';

const supabase = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!
);

export interface CostTracking {
  date: string;
  unitId: string;
  tokensUsed: number;
  costUSD: number;
  model: string;
}

export async function trackOpenAICost(
  unitId: string,
  tokensUsed: number,
  model: string,
  costUSD: number
): Promise<void> {
  await supabase.from('openai_cost_tracking').insert({
    unit_id: unitId,
    date: new Date().toISOString().split('T')[0],
    tokens_used: tokensUsed,
    cost_usd: costUSD,
    model,
  });
}

export async function getMonthlyOpenAICost(): Promise<number> {
  const startOfMonth = new Date();
  startOfMonth.setDate(1);
  startOfMonth.setHours(0, 0, 0, 0);

  const { data } = await supabase
    .from('openai_cost_tracking')
    .select('cost_usd')
    .gte('date', startOfMonth.toISOString().split('T')[0]);

  return (
    data?.reduce((sum, record) => sum + parseFloat(record.cost_usd), 0) || 0
  );
}

export async function checkCostThreshold(): Promise<{
  exceeded: boolean;
  current: number;
  threshold: number;
}> {
  const threshold = parseFloat(
    process.env.OPENAI_COST_ALERT_THRESHOLD || '100'
  );
  const current = await getMonthlyOpenAICost();

  if (current >= threshold * 0.8) {
    await sendTelegramAlert({
      message: `‚ö†Ô∏è Custo OpenAI pr√≥ximo do limite: $${current.toFixed(2)} / $${threshold}`,
      current,
      threshold,
    });
  }

  return {
    exceeded: current >= threshold,
    current,
    threshold,
  };
}
```

**Migration SQL:**

```sql
CREATE TABLE IF NOT EXISTS openai_cost_tracking (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  unit_id UUID REFERENCES units(id),
  date DATE NOT NULL,
  tokens_used INTEGER NOT NULL,
  cost_usd DECIMAL(10, 4) NOT NULL,
  model VARCHAR(50) NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW(),

  INDEX idx_date (date),
  INDEX idx_unit_date (unit_id, date)
);
```

## üÜï Observabilidade Avan√ßada

### Dashboard de Sa√∫de

Criar p√°gina `/app/admin/health` (protegida por role admin) que exibe:

- Status dos servi√ßos (Supabase, OpenAI, Telegram)
- √öltima execu√ß√£o de cada cron job
- Custos OpenAI do m√™s atual
- M√©tricas de performance (lat√™ncia, taxa de erro)
- Alertas recentes

### M√©tricas Customizadas

```typescript
// lib/metrics.ts
export interface SystemMetrics {
  etlSuccessRate: number;
  averageETLDuration: number;
  openaiCacheHitRate: number;
  circuitBreakerState: Record<string, CircuitState>;
  costSavingsFromCache: number;
}

export async function getSystemMetrics(): Promise<SystemMetrics> {
  // Buscar m√©tricas agregadas do Supabase
  const { data: etlRuns } = await supabase
    .from('etl_runs')
    .select('status, duration_seconds')
    .gte(
      'started_at',
      new Date(Date.now() - 30 * 24 * 60 * 60 * 1000).toISOString()
    );

  const totalRuns = etlRuns?.length || 0;
  const successfulRuns =
    etlRuns?.filter(r => r.status === 'SUCCESS').length || 0;
  const avgDuration =
    etlRuns?.reduce((sum, r) => sum + (r.duration_seconds || 0), 0) /
      totalRuns || 0;

  // Calcular cache hit rate
  const { data: cacheStats } = await supabase
    .from('openai_cache')
    .select('created_at')
    .gte(
      'created_at',
      new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString()
    );

  const cacheHits = cacheStats?.length || 0;
  // Estimar total de requisi√ß√µes (cache hits + misses)
  const estimatedTotalRequests = cacheHits * 2; // Assumindo 50% hit rate
  const cacheHitRate =
    estimatedTotalRequests > 0 ? (cacheHits / estimatedTotalRequests) * 100 : 0;

  return {
    etlSuccessRate: totalRuns > 0 ? (successfulRuns / totalRuns) * 100 : 0,
    averageETLDuration: avgDuration,
    openaiCacheHitRate: cacheHitRate,
    circuitBreakerState: {
      openai: openaiCircuitBreaker.getState(),
      telegram: telegramCircuitBreaker.getState(),
    },
    costSavingsFromCache: await calculateCacheSavings(),
  };
}
```

## üîµ Guia de Migra√ß√£o v3.0 ‚Üí v4.0

1. **Backup completo**: garantir backup do Supabase antes de iniciar.
2. **Criar branch `infra/v4`**: isolar mudan√ßas da produ√ß√£o.
3. **Aplicar migrations SQL**: criar tabelas `openai_cache`, `openai_cost_tracking` se n√£o existirem.
4. **Instalar depend√™ncias**: nenhuma nova depend√™ncia externa necess√°ria (usa Supabase Storage para cache).
5. **Implementar libs novas**: copiar `lib/idempotency.ts`, `lib/retry.ts`, `lib/circuitBreaker.ts`, `lib/cache.ts`, `lib/logger.ts`, `lib/monitoring.ts`, `lib/parallelProcessing.ts`.
6. **Atualizar cron jobs**: adicionar idempot√™ncia e structured logging em todos os cron jobs.
7. **Adicionar health checks**: criar `/app/api/cron/health-check/route.ts` e `/app/api/health/detailed/route.ts`.
8. **Configurar Vercel Cron**: adicionar cron `*/5 * * * *` para health check.
9. **Atualizar vari√°veis de ambiente**: adicionar `CRON_SECRET`, `OPENAI_COST_ALERT_THRESHOLD`, `HEALTH_CHECK_ENABLED`.
10. **Testar em preview**: validar todas as funcionalidades em ambiente de preview.
11. **Deploy gradual**: fazer deploy em produ√ß√£o e monitorar por 48h.
12. **Validar m√©tricas**: verificar dashboard de sa√∫de e custos OpenAI.

## üîµ Estimativa de Custos

- **Vercel**: plano Free cobre at√© 100 GB-h/m√™s; considerar Pro (~US$20) se cron e fun√ß√µes ultrapassarem limites.
- **OpenAI**: üÜï **Redu√ß√£o estimada de 40-60%** com cache inteligente. Estimativa original R$20-60/m√™s reduz para **R$12-36/m√™s**.
- **Supabase**: plano Starter (US$25) suficiente; upgrade para Pro se passar de 8 GB ou precisar de r√©plicas.
- **Telegram**: sem custo adicional.
- üÜï **Cache Storage**: uso m√≠nimo de Supabase Storage para cache (~100MB/m√™s), incluso no plano Starter.
  > üü¢ **Boa pr√°tica:** criar alertas financeiros na Vercel, Supabase e OpenAI para 80% do or√ßamento previsto.
  > üü¢ **Boa pr√°tica:** monitorar custos OpenAI diariamente via dashboard `/app/admin/health`.

## üîµ Crit√©rios de Aceite (Quality Gate)

1. ‚úÖ Documento n√£o cont√©m refer√™ncias pendentes a VPS, Python 3.12, FastAPI, Celery/RQ ou Ollama.
2. ‚úÖ Diagramas e fluxos representam apenas Next.js/Vercel, Supabase, OpenAI e Telegram.
3. ‚úÖ Se√ß√£o de seguran√ßa descreve CSP/HSTS, RLS e uso do OpenAI com anonimiza√ß√£o.
4. ‚úÖ Cron Vercel documentado com hor√°rio e regi√£o.
5. ‚úÖ Configura√ß√µes `.env` alinhadas ao stack serverless.
6. ‚úÖ Guia de migra√ß√£o presente com passos execut√°veis.
7. ‚úÖ Custos atualizados e coerentes com redu√ß√£o estimada de cache.
8. ‚úÖ Links e tabelas revisados (sem quebras), com emojis padr√£o.
9. üÜï **Idempot√™ncia implementada** em todos os cron jobs.
10. üÜï **Health checks autom√°ticos** configurados e testados.
11. üÜï **Circuit breaker** implementado para OpenAI e Telegram.
12. üÜï **Cache de an√°lises** funcionando e reduzindo custos.
13. üÜï **Structured logging** implementado em todas as rotas cr√≠ticas.
14. üÜï **Monitoramento de custos** ativo e alertando corretamente.

## üîµ Changelog

- **v4.0** (8 de novembro de 2025):
  - üÜï Idempot√™ncia garantida em todos os cron jobs
  - üÜï Health checks autom√°ticos a cada 5 minutos
  - üÜï Retry com backoff exponencial para APIs externas
  - üÜï Cache inteligente para an√°lises OpenAI (redu√ß√£o de 40-60% nos custos)
  - üÜï Circuit breaker para prote√ß√£o contra falhas em cascata
  - üÜï Processamento paralelo no ETL (batches de 5 unidades)
  - üÜï Structured logging com correlation IDs
  - üÜï Monitoramento proativo de custos OpenAI
  - üÜï Dashboard de sa√∫de e m√©tricas customizadas
  - Melhorias na observabilidade e resili√™ncia geral

- **v3.0**: migra√ß√£o total para Vercel + Next.js, remo√ß√£o de VPS e stack Python, ado√ß√£o de OpenAI API e cron jobs gerenciados, nova se√ß√£o de migra√ß√£o e crit√©rios de aceite.

## üîµ Resumo Final

- Arquitetura consolidada na Vercel com Next.js, Supabase e OpenAI, eliminando servidores pr√≥prios.
- üÜï **Resili√™ncia enterprise**: idempot√™ncia, circuit breaker, retry inteligente e health checks proativos.
- üÜï **Otimiza√ß√£o de custos**: cache reduz custos OpenAI em 40-60%, monitoramento proativo previne surpresas.
- üÜï **Observabilidade completa**: structured logging, m√©tricas customizadas e dashboard de sa√∫de.
- Cron jobs, seguran√ßa e observabilidade agora centralizados no ecossistema da Vercel, com alertas Telegram.
- Guia de migra√ß√£o, custos e crit√©rios de aceite garantem transi√ß√£o controlada para o stack 100% serverless com resili√™ncia de n√≠vel enterprise.

üìò Para detalhes de arquitetura de c√≥digo (componentes e padr√µes), veja [02_ARCHITECTURE.md](docs/02_ARCHITECTURE.md).
